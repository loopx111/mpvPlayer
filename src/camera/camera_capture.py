"""
AIå¢å¼ºçš„æ‘„åƒå¤´æ§åˆ¶å™¨

åœ¨ç°æœ‰CameraControlleråŸºç¡€ä¸Šæ·»åŠ AIåˆ†æåŠŸèƒ½ï¼Œ
æ”¯æŒYOLOv5äººæ•°è¯†åˆ«å’Œæ ¸å¿ƒç»‘å®šä¼˜åŒ–ã€‚
"""

import time
import threading
import cv2
import numpy as np
from typing import Optional, Callable, Dict
from PySide6 import QtCore, QtWidgets, QtGui
from PySide6.QtCore import QThread, Signal

from src.player.camera_controller import CameraController, CameraWidget, CameraThread
from src.ai.yolo_detector import YOLOv5Detector, DetectionResult
from src.ai.people_counter import PeopleCounter, PeopleCountStats
from src.ai.core_binding import CoreBindingManager, create_4core_optimized_config


class VideoAnalyzer(QThread):
    """è§†é¢‘åˆ†æçº¿ç¨‹ - è´Ÿè´£AIæ¨ç†å’Œäººæ•°ç»Ÿè®¡"""
    
    analysis_complete = Signal(dict)  # åˆ†æå®Œæˆä¿¡å·
    
    def __init__(self, model_path: str, core_binding_manager: CoreBindingManager):
        super().__init__()
        self.model_path = model_path
        self.core_binding_manager = core_binding_manager
        
        # AIç»„ä»¶
        self.detector = None
        self.people_counter = PeopleCounter()
        
        # çº¿ç¨‹æ§åˆ¶
        self.running = False
        self.current_frame = None
        self.frame_lock = threading.Lock()
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šé™ä½åˆ†æé¢‘ç‡ï¼Œå‡å°‘CPUå ç”¨
        self.max_analysis_fps = 10  # æœ€å¤§åˆ†æé¢‘ç‡ï¼š2å¸§/ç§’
        self.last_analysis_time = 0
        
        # æ€§èƒ½ç»Ÿè®¡
        self.analysis_count = 0
        self.total_analysis_time = 0.0
    
    def run(self):
        """çº¿ç¨‹è¿è¡Œå‡½æ•°"""
        try:
            print("[AIåˆ†æå™¨] çº¿ç¨‹å¯åŠ¨...")
            
            # ç»‘å®šåˆ°AIæ ¸å¿ƒ
            self.core_binding_manager.bind_ai_inference_thread(self)
            
            # åˆå§‹åŒ–YOLOv5æ£€æµ‹å™¨
            print(f"[AIåˆ†æå™¨] åŠ è½½æ¨¡å‹: {self.model_path}")
            self.detector = YOLOv5Detector(
                model_path=self.model_path,
                conf_threshold=0.6,  # è¾ƒé«˜çš„ç½®ä¿¡åº¦é˜ˆå€¼ç¡®ä¿å‡†ç¡®æ€§
                core_affinity=self.core_binding_manager.config.ai_cores
            )
            
            self.running = True
            print("[AIåˆ†æå™¨] åˆ†æå™¨å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹åˆ†æ...")
            
            while self.running:
                current_time = time.time()
                
                # æ€§èƒ½ä¼˜åŒ–ï¼šæ§åˆ¶åˆ†æé¢‘ç‡ï¼Œé¿å…è¿‡é«˜CPUå ç”¨
                time_since_last_analysis = current_time - self.last_analysis_time
                if time_since_last_analysis < (1.0 / self.max_analysis_fps):
                    # ç­‰å¾…è¶³å¤Ÿçš„æ—¶é—´é—´éš”
                    time.sleep(0.05)  # å°ç¡çœ å‡å°‘CPUå ç”¨
                    continue
                
                start_time = time.time()
                
                # è·å–å½“å‰å¸§
                with self.frame_lock:
                    if self.current_frame is None:
                        # æ²¡æœ‰æ–°å¸§ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´
                        time.sleep(0.05)
                        continue
                    
                    frame = self.current_frame.copy()
                    self.current_frame = None  # æ¸…ç©ºå½“å‰å¸§ï¼Œç­‰å¾…æ–°å¸§
                
                # æ‰§è¡ŒAIåˆ†æ
                if frame is not None and frame.size > 0:
                    print(f"[AIåˆ†æå™¨] æ¥æ”¶åˆ°æ–°å¸§ï¼Œå°ºå¯¸: {frame.shape}")
                    analysis_result = self._analyze_frame(frame)
                    
                    # å‘é€åˆ†æç»“æœ
                    print(f"[AIåˆ†æå™¨] åˆ†æå®Œæˆï¼Œå‘é€ç»“æœ: {analysis_result.get('detection_result').person_count}äºº")
                    self.analysis_complete.emit(analysis_result)
                    
                    # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                    analysis_time = (time.time() - start_time) * 1000
                    self.analysis_count += 1
                    self.total_analysis_time += analysis_time
                    self.last_analysis_time = current_time
                else:
                    print("[AIåˆ†æå™¨] æ¥æ”¶åˆ°ç©ºå¸§æˆ–æ— æ•ˆå¸§ï¼Œè·³è¿‡åˆ†æ")
                    
        except Exception as e:
            print(f"[AIåˆ†æå™¨] è§†é¢‘åˆ†æçº¿ç¨‹é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.running = False
            print("[AIåˆ†æå™¨] çº¿ç¨‹åœæ­¢")
    
    def _analyze_frame(self, frame: np.ndarray) -> Dict:
        """åˆ†æå•å¸§å›¾åƒ"""
        print(f"[AIåˆ†æå™¨] å¼€å§‹åˆ†æç¬¬ {self.analysis_count + 1} å¸§")
        
        # æ‰§è¡ŒYOLOv5äººæ•°æ£€æµ‹
        detection_result = self.detector.detect_people(frame)
        
        print(f"[AIåˆ†æå™¨] æ£€æµ‹ç»“æœ: {detection_result.person_count} äºº")
        print(f"[AIåˆ†æå™¨] æ£€æµ‹æ¡†åæ ‡: {detection_result.detections}")
        
        # æ›´æ–°äººæ•°ç»Ÿè®¡
        count_update = self.people_counter.update_count(
            detection_result.person_count, 
            time.time()
        )
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.people_counter.get_statistics()
        
        # æ€§èƒ½ä¿¡æ¯
        detector_stats = self.detector.get_performance_stats()
        
        print(f"[AIåˆ†æå™¨] æ€§èƒ½ç»Ÿè®¡: FPS={round(1000 / detector_stats['avg_inference_time_ms'], 2)}, å»¶è¿Ÿ={detector_stats['avg_inference_time_ms']}ms")
        
        return {
            'detection_result': detection_result,
            'count_update': count_update,
            'statistics': stats,
            'performance': {
                'analysis_fps': round(1000 / detector_stats['avg_inference_time_ms'], 2),
                'avg_analysis_time_ms': detector_stats['avg_inference_time_ms'],
                'total_analyses': self.analysis_count
            },
            'timestamp': time.time()
        }
    
    def update_frame(self, frame: np.ndarray):
        """æ›´æ–°å¾…åˆ†æå¸§"""
        with self.frame_lock:
            self.current_frame = frame
    
    def stop_analysis(self):
        """åœæ­¢åˆ†æ"""
        self.running = False
        self.wait(3000)  # ç­‰å¾…3ç§’


class AICameraWidget(CameraWidget):
    """AIå¢å¼ºçš„æ‘„åƒå¤´æ˜¾ç¤ºæ§ä»¶"""
    
    def __init__(self, parent=None):
        super().__init__(parent)
        
        # AIåˆ†æç»“æœæ˜¾ç¤º
        self.detection_overlay = True  # æ˜¯å¦æ˜¾ç¤ºæ£€æµ‹æ¡†
        self.current_detections = []
        self.analysis_info = {}
        
        # ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        self.info_text = ""
        
        # è‡ªå®šä¹‰æ ·å¼
        self.setStyleSheet("""
            QLabel {
                border: 2px solid #4CAF50;
                border-radius: 8px;
                background-color: #f8f9fa;
                color: #2c3e50;
                font-size: 12px;
                font-family: 'Segoe UI', Arial, sans-serif;
            }
        """)
    
    def update_analysis_info(self, analysis_result: Dict):
        """æ›´æ–°åˆ†æä¿¡æ¯"""
        self.analysis_info = analysis_result
        
        # æ›´æ–°æ£€æµ‹ç»“æœ
        if 'detection_result' in analysis_result:
            self.current_detections = analysis_result['detection_result'].detections
        
        # æ›´æ–°ä¿¡æ¯æ–‡æœ¬
        self._update_info_text()
        
        # è§¦å‘é‡ç»˜
        self.update()
    
    def _update_info_text(self):
        """æ›´æ–°ä¿¡æ¯æ˜¾ç¤ºæ–‡æœ¬"""
        if not self.analysis_info:
            self.info_text = "AIåˆ†æå‡†å¤‡ä¸­...\nç­‰å¾…æ‘„åƒå¤´å¸§"
            return
        
        stats = self.analysis_info.get('statistics', PeopleCountStats())
        perf = self.analysis_info.get('performance', {})
        detection_result = self.analysis_info.get('detection_result', None)
        
        # åŸºç¡€ä¿¡æ¯ - ç›´æ¥è®¿é—®dataclasså±æ€§
        info_lines = [
            f"ğŸ‘¥ å½“å‰äººæ•°: {stats.current_count}",
            f"ğŸ“Š å¹³å‡äººæ•°: {stats.avg_count}",
            f"ğŸ“ˆ è¶‹åŠ¿: {stats.trend}",
            f"âš¡ åˆ†æFPS: {perf.get('analysis_fps', 0)}",
            f"â±ï¸ å»¶è¿Ÿ: {perf.get('avg_analysis_time_ms', 0)}ms",
            f"ğŸ”„ æ€»åˆ†ææ¬¡æ•°: {perf.get('total_analyses', 0)}"
        ]
        
        # æ·»åŠ æ£€æµ‹è¯¦æƒ…
        if detection_result:
            info_lines.append(f"ğŸ” æœ¬æ¬¡æ£€æµ‹: {detection_result.person_count}äºº")
            info_lines.append(f"ğŸ“ æ£€æµ‹æ¡†æ•°: {len(detection_result.detections)}")
            if detection_result.detections:
                confidences = [f"{d[4]:.2f}" for d in detection_result.detections]
                info_lines.append(f"ğŸ¯ ç½®ä¿¡åº¦: {', '.join(confidences)}")
        
        self.info_text = '\n'.join(info_lines)
    
    def paintEvent(self, event):
        """é‡ç»˜äº‹ä»¶ - æ·»åŠ AIåˆ†æä¿¡æ¯æ˜¾ç¤º"""
        super().paintEvent(event)
        
        # å¦‚æœå½“å‰æœ‰å›¾åƒï¼Œç»˜åˆ¶æ£€æµ‹æ¡†å’Œä¿¡æ¯
        if self.current_frame is not None:
            painter = QtGui.QPainter(self)
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            if self.detection_overlay and self.current_detections:
                self._draw_detections(painter)
            
            # ç»˜åˆ¶ä¿¡æ¯é¢æ¿
            self._draw_info_panel(painter)
            
            painter.end()
    
    def _draw_detections(self, painter: QtGui.QPainter):
        """ç»˜åˆ¶æ£€æµ‹æ¡†"""
        # å¦‚æœæ²¡æœ‰æ£€æµ‹ç»“æœï¼Œç›´æ¥è¿”å›
        if not self.current_detections:
            return
            
        # è®¡ç®—å›¾åƒåœ¨æ§ä»¶ä¸­çš„å®é™…æ˜¾ç¤ºåŒºåŸŸ
        pixmap = self.pixmap()
        if not pixmap:
            return
        
        # è·å–å›¾åƒåœ¨æ§ä»¶ä¸­çš„ä½ç½®å’Œå°ºå¯¸
        pixmap_rect = self._get_pixmap_rect()
        
        # åŸå§‹å›¾åƒå°ºå¯¸
        orig_width = self.current_frame.shape[1]
        orig_height = self.current_frame.shape[0]
        
        # ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
        scale_x = pixmap_rect.width() / orig_width if orig_width > 0 else 1
        scale_y = pixmap_rect.height() / orig_height if orig_height > 0 else 1
        scale = min(scale_x, scale_y)  # ä½¿ç”¨è¾ƒå°çš„æ¯”ä¾‹ä¿æŒå®½é«˜æ¯”
        
        # è®¡ç®—å®é™…æ˜¾ç¤ºåŒºåŸŸï¼ˆå±…ä¸­æ˜¾ç¤ºï¼‰
        actual_width = int(orig_width * scale)
        actual_height = int(orig_height * scale)
        actual_x = pixmap_rect.x() + (pixmap_rect.width() - actual_width) // 2
        actual_y = pixmap_rect.y() + (pixmap_rect.height() - actual_height) // 2
        
        # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹æ¡†
        for detection in self.current_detections:
            x1, y1, x2, y2, conf, class_name = detection
            
            # ç¼©æ”¾åæ ‡åˆ°æ˜¾ç¤ºå°ºå¯¸
            x1_scaled = int(x1 * scale) + actual_x
            y1_scaled = int(y1 * scale) + actual_y
            x2_scaled = int(x2 * scale) + actual_x
            y2_scaled = int(y2 * scale) + actual_y
            
            # ç¡®ä¿åæ ‡åœ¨æ˜¾ç¤ºåŒºåŸŸå†…
            x1_scaled = max(actual_x, min(x1_scaled, actual_x + actual_width))
            y1_scaled = max(actual_y, min(y1_scaled, actual_y + actual_height))
            x2_scaled = max(actual_x, min(x2_scaled, actual_x + actual_width))
            y2_scaled = max(actual_y, min(y2_scaled, actual_y + actual_height))
            
            # è®¡ç®—è¾¹ç•Œæ¡†å°ºå¯¸
            bbox_width = max(1, x2_scaled - x1_scaled)
            bbox_height = max(1, y2_scaled - y1_scaled)
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            painter.setPen(QtGui.QPen(QtGui.QColor(0, 255, 0), 3))
            painter.drawRect(x1_scaled, y1_scaled, bbox_width, bbox_height)
            
            # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
            label = f'{class_name} {conf:.2f}'
            label_rect_width = len(label) * 7 + 10
            label_rect_height = 20
            
            # ç¡®ä¿æ ‡ç­¾ä¸è¶…å‡ºæ§ä»¶è¾¹ç•Œ
            label_x = max(0, min(x1_scaled, self.width() - label_rect_width))
            label_y = max(0, y1_scaled - label_rect_height - 5)
            
            painter.setPen(QtGui.QPen(QtGui.QColor(0, 0, 0)))
            painter.setBrush(QtGui.QBrush(QtGui.QColor(0, 255, 0, 200)))
            painter.drawRect(label_x, label_y, label_rect_width, label_rect_height)
            
            # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
            painter.setPen(QtGui.QPen(QtGui.QColor(255, 255, 255)))
            painter.setFont(QtGui.QFont('Segoe UI', 8, QtGui.QFont.Bold))
            painter.drawText(label_x + 5, label_y + 14, label)
    
    def _draw_info_panel(self, painter: QtGui.QPainter):
        """ç»˜åˆ¶ä¿¡æ¯é¢æ¿"""
        if not self.info_text:
            return
        
        # è·å–å›¾åƒåœ¨æ§ä»¶ä¸­çš„æ˜¾ç¤ºåŒºåŸŸ
        pixmap_rect = self._get_pixmap_rect()
        if pixmap_rect.isEmpty():
            return
        
        # ä¿¡æ¯é¢æ¿ä½ç½®ï¼ˆæ‘„åƒå¤´ç”»é¢å³ä¾§ï¼Œç¡®ä¿ä¸è¶…å‡ºæ§ä»¶è¾¹ç•Œï¼‰
        info_width = 180
        info_height = 140
        info_x = pixmap_rect.right() + 10
        info_y = pixmap_rect.top()
        
        # ç¡®ä¿ä¿¡æ¯é¢æ¿ä¸è¶…å‡ºæ§ä»¶è¾¹ç•Œ
        widget_width = self.width()
        if info_x + info_width > widget_width:
            info_x = widget_width - info_width - 5
        
        # ç»˜åˆ¶èƒŒæ™¯ï¼ˆåŠé€æ˜ï¼‰
        painter.setBrush(QtGui.QBrush(QtGui.QColor(255, 255, 255, 230)))
        painter.setPen(QtGui.QPen(QtGui.QColor(0, 0, 0, 120)))
        painter.drawRect(info_x, info_y, info_width, info_height)
        
        # ç»˜åˆ¶æ ‡é¢˜æ 
        painter.setBrush(QtGui.QBrush(QtGui.QColor(76, 175, 80, 200)))
        painter.drawRect(info_x, info_y, info_width, 25)
        
        # ç»˜åˆ¶æ ‡é¢˜
        painter.setPen(QtGui.QPen(QtGui.QColor(255, 255, 255)))
        painter.setFont(QtGui.QFont('Segoe UI', 10, QtGui.QFont.Bold))
        painter.drawText(info_x + 5, info_y + 17, "AIåˆ†æç»“æœ")
        
        # ç»˜åˆ¶å†…å®¹æ–‡æœ¬
        painter.setPen(QtGui.QPen(QtGui.QColor(0, 0, 0)))
        painter.setFont(QtGui.QFont('Segoe UI', 9))
        
        lines = self.info_text.split('\n')
        for i, line in enumerate(lines):
            painter.drawText(info_x + 8, info_y + 45 + i * 20, line)
    
    def _get_pixmap_rect(self) -> QtCore.QRect:
        """è·å–å›¾åƒåœ¨æ§ä»¶ä¸­çš„æ˜¾ç¤ºåŒºåŸŸ"""
        pixmap = self.pixmap()
        if not pixmap:
            return QtCore.QRect()
        
        pixmap_size = pixmap.size()
        widget_size = self.size()
        
        # è®¡ç®—å±…ä¸­æ˜¾ç¤ºçš„åŒºåŸŸ
        x = (widget_size.width() - pixmap_size.width()) // 2
        y = (widget_size.height() - pixmap_size.height()) // 2
        
        return QtCore.QRect(x, y, pixmap_size.width(), pixmap_size.height())


class AICameraController(CameraController):
    """AIå¢å¼ºçš„æ‘„åƒå¤´æ§åˆ¶å™¨"""
    
    def __init__(self):
        super().__init__()
        
        # AIåˆ†æç»„ä»¶
        self.video_analyzer = None
        self.core_binding_manager = CoreBindingManager(create_4core_optimized_config())
        
        # AIåˆ†æçŠ¶æ€
        self.ai_enabled = False
        self.analysis_results = {}
        
        # å›è°ƒå‡½æ•°
        self.on_analysis_result = None
    
    def initialize(self, camera_index: int = None, resolution: tuple = (640, 480), 
                   fps: int = 30, enable_ai: bool = False, model_path: str = None):
        """åˆå§‹åŒ–æ‘„åƒå¤´æ§åˆ¶å™¨ï¼ˆæ‰©å±•AIåŠŸèƒ½ï¼‰"""
        # ä¿å­˜å½“å‰AIçŠ¶æ€
        ai_was_enabled = self.ai_enabled
        
        # å…ˆç¦ç”¨AIåˆ†æï¼ˆå¦‚æœæ­£åœ¨è¿è¡Œï¼‰
        if self.ai_enabled:
            print("[AIæ§åˆ¶å™¨] é‡æ–°åˆå§‹åŒ–ï¼Œå…ˆç¦ç”¨AIåˆ†æ...")
            self.disable_ai_analysis()
        
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        success = super().initialize(camera_index, resolution, fps)
        
        if success and (enable_ai or ai_was_enabled):
            # æ›¿æ¢ä¸ºAIå¢å¼ºçš„æ§ä»¶
            self.camera_widget = AICameraWidget()
            
            # åˆå§‹åŒ–AIåˆ†æ
            ai_success = self.enable_ai_analysis(model_path)
            
            if not ai_success:
                print("[AIæ§åˆ¶å™¨] âœ— AIåˆ†æåˆå§‹åŒ–å¤±è´¥ï¼Œä½†æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ")
                # å³ä½¿AIå¤±è´¥ï¼Œæ‘„åƒå¤´ä»ç„¶å¯ä»¥å·¥ä½œ
        
        return success
    
    def enable_ai_analysis(self, model_path: str = None):
        """å¯ç”¨AIåˆ†æåŠŸèƒ½"""
        try:
            if model_path is None:
                # ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„
                model_path = "models/yolov5s.onnx"
            
            print("[AIæ§åˆ¶å™¨] å¼€å§‹å¯ç”¨AIåˆ†æåŠŸèƒ½...")
            
            # ç¡®ä¿å…ˆç¦ç”¨å·²æœ‰çš„AIåˆ†æï¼ˆé˜²æ­¢é‡å¤åˆå§‹åŒ–ï¼‰
            if self.ai_enabled and self.video_analyzer:
                print("[AIæ§åˆ¶å™¨] æ£€æµ‹åˆ°å·²æœ‰AIåˆ†æå™¨ï¼Œå…ˆç¦ç”¨...")
                self.disable_ai_analysis()
            
            # æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦å·²å¯åŠ¨
            if not self.camera_thread or not self.camera_thread.isRunning():
                print("[AIæ§åˆ¶å™¨] æ‘„åƒå¤´æœªå¯åŠ¨ï¼Œå…ˆå¯åŠ¨æ‘„åƒå¤´...")
                if not self.start_camera():
                    print("[AIæ§åˆ¶å™¨] âœ— æ‘„åƒå¤´å¯åŠ¨å¤±è´¥ï¼Œæ— æ³•å¯ç”¨AIåˆ†æ")
                    return False
            
            # ç¡®ä¿ä½¿ç”¨AIå¢å¼ºçš„æ§ä»¶
            if not isinstance(self.camera_widget, AICameraWidget):
                print("[AIæ§åˆ¶å™¨] æ›¿æ¢ä¸ºAIå¢å¼ºæ§ä»¶...")
                self.camera_widget = AICameraWidget()
            
            # åˆ›å»ºè§†é¢‘åˆ†æå™¨
            print("[AIæ§åˆ¶å™¨] åˆ›å»ºè§†é¢‘åˆ†æå™¨...")
            self.video_analyzer = VideoAnalyzer(model_path, self.core_binding_manager)
            
            # è¿æ¥ä¿¡å·
            print("[AIæ§åˆ¶å™¨] è¿æ¥åˆ†æå®Œæˆä¿¡å·...")
            self.video_analyzer.analysis_complete.connect(self._on_analysis_complete)
            
            # å¯åŠ¨åˆ†æçº¿ç¨‹
            print("[AIæ§åˆ¶å™¨] å¯åŠ¨åˆ†æçº¿ç¨‹...")
            self.video_analyzer.start()
            
            # ç­‰å¾…åˆ†æå™¨å¯åŠ¨å®Œæˆ
            time.sleep(0.5)
            
            # æ£€æŸ¥åˆ†æå™¨æ˜¯å¦æˆåŠŸå¯åŠ¨
            if not self.video_analyzer.isRunning():
                print("[AIæ§åˆ¶å™¨] âœ— AIåˆ†æå™¨å¯åŠ¨å¤±è´¥")
                self.video_analyzer = None
                self.ai_enabled = False
                return False
            
            # æœ€åè®¾ç½®å¸§å›è°ƒï¼Œç¡®ä¿åˆ†æå™¨å·²å‡†å¤‡å¥½æ¥æ”¶å¸§
            print("[AIæ§åˆ¶å™¨] è®¾ç½®å¸§å›è°ƒ...")
            self.set_frame_callback(self._on_camera_frame_for_ai)
            
            self.ai_enabled = True
            print("âœ“ AIåˆ†æåŠŸèƒ½å·²å¯ç”¨")
            print("[AIæ§åˆ¶å™¨] AIåˆ†æå™¨çŠ¶æ€: è¿è¡Œä¸­={}".format(self.video_analyzer.isRunning()))
            print("[AIæ§åˆ¶å™¨] æ‘„åƒå¤´çŠ¶æ€: è¿è¡Œä¸­={}".format(self.camera_thread.isRunning() if self.camera_thread else False))
            
            return True
            
        except Exception as e:
            print("âœ— å¯ç”¨AIåˆ†æå¤±è´¥: {}".format(e))
            self.ai_enabled = False
            self.video_analyzer = None
            return False
    
    def disable_ai_analysis(self):
        """ç¦ç”¨AIåˆ†æåŠŸèƒ½"""
        try:
            # æ¸…ç†å¸§å›è°ƒ
            if hasattr(self, 'frame_callback') and self.frame_callback:
                self.frame_callback = None
            
            # åœæ­¢å¹¶æ¸…ç†åˆ†æå™¨
            if self.video_analyzer:
                print("[AIæ§åˆ¶å™¨] åœæ­¢AIåˆ†æå™¨...")
                self.video_analyzer.stop_analysis()
                
                # ç­‰å¾…åˆ†æå™¨å®Œå…¨åœæ­¢
                if self.video_analyzer.isRunning():
                    self.video_analyzer.wait(2000)  # ç­‰å¾…2ç§’
                
                # æ–­å¼€ä¿¡å·è¿æ¥
                try:
                    self.video_analyzer.analysis_complete.disconnect()
                except:
                    pass  # å¿½ç•¥æ–­å¼€è¿æ¥é”™è¯¯
                
                self.video_analyzer = None
                print("[AIæ§åˆ¶å™¨] AIåˆ†æå™¨å·²åœæ­¢")
            
            self.ai_enabled = False
            self.analysis_results = {}
            print("âœ“ AIåˆ†æåŠŸèƒ½å·²ç¦ç”¨")
            
        except Exception as e:
            print(f"âœ— ç¦ç”¨AIåˆ†ææ—¶å‡ºé”™: {e}")
            self.ai_enabled = False
            self.video_analyzer = None
    
    def _on_camera_frame_for_ai(self, frame: np.ndarray):
        """æ‘„åƒå¤´å¸§å›è°ƒï¼ˆç”¨äºAIåˆ†æï¼‰"""
        print("[å¸§å›è°ƒ] æ‘„åƒå¤´å¸§å›è°ƒè¢«è°ƒç”¨ï¼Œå¸§: {}, AIå¯ç”¨: {}, åˆ†æå™¨: {}, è¿è¡Œä¸­: {}".format(
            "æœ‰æ•ˆ" if frame is not None and frame.size > 0 else "æ— æ•ˆ",
            self.ai_enabled,
            "å­˜åœ¨" if self.video_analyzer else "ä¸å­˜åœ¨",
            self.video_analyzer.isRunning() if self.video_analyzer else False
        ))
        
        if self.ai_enabled and self.video_analyzer and self.video_analyzer.isRunning():
            # ç¡®ä¿å¸§æœ‰æ•ˆ
            if frame is not None and frame.size > 0:
                print("[å¸§å›è°ƒ] æ¥æ”¶åˆ°æ–°å¸§ï¼Œå°ºå¯¸: {}ï¼Œå‡†å¤‡ä¼ é€’ç»™AIåˆ†æå™¨".format(frame.shape))
                self.video_analyzer.update_frame(frame)
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå¸§æ›´æ–°é¢‘ç‡
                if not hasattr(self, '_last_frame_time'):
                    self._last_frame_time = time.time()
                else:
                    current_time = time.time()
                    frame_interval = current_time - self._last_frame_time
                    if frame_interval > 1.0:  # è¶…è¿‡1ç§’æ²¡æœ‰å¸§æ›´æ–°
                        print("[å¸§å›è°ƒ] å¸§æ›´æ–°é—´éš”: {:.2f}s (å¯èƒ½å¤ªæ…¢)".format(frame_interval))
                    self._last_frame_time = current_time
            else:
                print("[å¸§å›è°ƒ] æ¥æ”¶åˆ°æ— æ•ˆå¸§ï¼Œè·³è¿‡")
        else:
            print("[å¸§å›è°ƒ] æ¡ä»¶ä¸æ»¡è¶³ï¼Œè·³è¿‡å¸§å¤„ç†")
    
    def _on_analysis_complete(self, analysis_result: Dict):
        """AIåˆ†æå®Œæˆå›è°ƒ"""
        # æ›´æ–°åˆ†æç»“æœ
        self.analysis_results = analysis_result
        
        # æ›´æ–°æ§ä»¶æ˜¾ç¤º
        if isinstance(self.camera_widget, AICameraWidget):
            self.camera_widget.update_analysis_info(analysis_result)
        
        # è°ƒç”¨ç”¨æˆ·å›è°ƒ
        if self.on_analysis_result:
            self.on_analysis_result(analysis_result)
    
    def set_analysis_callback(self, callback: Callable):
        """è®¾ç½®åˆ†æç»“æœå›è°ƒ"""
        self.on_analysis_result = callback
    
    def get_analysis_stats(self) -> Dict:
        """è·å–åˆ†æç»Ÿè®¡ä¿¡æ¯"""
        return self.analysis_results
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´ï¼ˆæ‰©å±•AIåœæ­¢ï¼‰"""
        # å…ˆåœæ­¢AIåˆ†æ
        self.disable_ai_analysis()
        
        # å†åœæ­¢æ‘„åƒå¤´
        super().stop_camera()


def create_ai_camera_controller() -> AICameraController:
    """åˆ›å»ºAIæ‘„åƒå¤´æ§åˆ¶å™¨å®ä¾‹"""
    return AICameraController()